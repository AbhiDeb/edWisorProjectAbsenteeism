{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "XYZ is a courier company. As we appreciate that human capital plays an important role\n",
    "in collection, transportation and delivery. The company is passing through genuine\n",
    "issue of Absenteeism. The company has shared it dataset and requested to have an\n",
    "answer on the following areas:\n",
    "1. What changes company should bring to reduce the number of absenteeism?\n",
    "2. How much losses every month can we project in 2011 if same trend of absenteeism continues?\n",
    "\n",
    "**Input Data**\n",
    "*Absenteeism_at_work_Project.xls*\n",
    "\n",
    "**Output Data**\n",
    "*Solution to given problems, i.e. inferences based on analysis and losses we can project in 2011 if same trend of absenteeism continues*\n",
    "\n",
    "### Data\n",
    "\n",
    "Our task is to analyse the given data and derive meaningful inferences. Given below is a sample of the data set that we are using:\n",
    "\n",
    "\n",
    "**Absenteeism_at_work_Project Sample Data (1-5 columns)**\n",
    "\n",
    "| ID | Reason for absence | Month of absence | Day of the week | Seasons |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| 11 | 26 | 7 | 3 | 1 |\n",
    "| 36 | 0 | 7 | 3 | 1 |\n",
    "| 3 | 23 | 7 | 4 | 1 |\n",
    "| 7 | 7 | 7 | 5 | 1 |\n",
    "| 11 | 23 | 7 | 5 | 1 |\n",
    "\n",
    "**Absenteeism_at_work_Project Sample Data (6-10 columns)**\n",
    "\n",
    "| Transportation expense | Distance | Service time | Age | Work load Average/day |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| 289 | 36 | 13 | 33 | 239,554 |\n",
    "| 118 | 13 | 18 | 50 | 239,554 |\n",
    "| 179 | 51 | 18 | 38 | 239,554 |\n",
    "| 279 | 5 | 14 | 39 | 239,554 |\n",
    "| 289 | 36 | 13 | 33 | 239,554 |\n",
    "\n",
    "\n",
    "\n",
    "**Absenteeism_at_work_Project Sample Data (11-15 columns)**\n",
    "\n",
    "| Hit target | Disciplinary failure | Education | Son | Social drinker |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| 97 | 0 | 1 | 2 | 1 |\n",
    "| 97 | 1 | 1 | 1 | 1 |\n",
    "| 97 | 0 | 1 | 0 | 1 |\n",
    "| 97 | 0 | 1 | 2 | 1 |\n",
    "| 97 | 0 | 1 | 2 | 1 |\n",
    "\n",
    "**Absenteeism_at_work_Project Sample Data (16-21 columns)**\n",
    "\n",
    "| Social smoker | Pet | Weight | Height | Body mass index | Absenteeism time in hours |\n",
    "| --- | --- | --- | --- | --- | --- |\n",
    "| 0 | 1 | 90 | 172 | 30 | 4 |\n",
    "| 0 | 0 | 98 | 178 | 31 | 0 |\n",
    "| 0 | 0 | 89 | 170 | 31 | 2 |\n",
    "| 1 | 0 | 68 | 168 | 24 | 4 |\n",
    "| 0 | 1 | 90 | 172 | 30 | 2 |\n",
    "\n",
    "Hence, we have below 21 predictors which we will use to analyse the Absenteeism trend with the employees.\n",
    "\n",
    "\n",
    "###### **Predictors**\n",
    "\n",
    "\n",
    "| S. No. | Predictors | Type |\n",
    "| --- | --- | --- |\n",
    "| 1. | ID | Categorical |\n",
    "| 2. | Reason for absence | Categorical |\n",
    "| 3. | Month of absence | Categorical |\n",
    "| 4. | Day of the week | Categorical |\n",
    "| 5. | Seasons | Categorical |\n",
    "| 6. | Transportation expense | Continuous |\n",
    "| 7. | Distance from Residence to Work | Continuous |\n",
    "| 8. | Service time | Continuous |\n",
    "| 9. | Age | Continuous |\n",
    "| 10. | Work load Average/day | Continuous |\n",
    "| 11. | Hit target | Continuous |\n",
    "| 12. | Disciplinary failure | Categorical |\n",
    "| 13. | Education | Categorical |\n",
    "| 14. | Son | Continuous |\n",
    "| 15. | Social drinker | Categorical |\n",
    "| 16. | Social smoker | Categorical |\n",
    "| 17. | Pet | Continuous |\n",
    "| 18. | Weight | Continuous |\n",
    "| 19. | Height | Continuous |\n",
    "| 20. | Body mass index | Continuous |\n",
    "| 21. | Absenteeism time in hours | Continuous |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2\n",
    "\n",
    "## Exploratory Data Analysis\n",
    "\n",
    "### Univariate Analysis\n",
    "\n",
    "Exploratory data analysis is most important step before we can apply any machine learning model. It specifically cleans up the data for the model, so that the model can work as expected from it, and not get any unexplained predictions. It involves various steps which are explained below.\n",
    "\n",
    "Similarly for more complex exploratory data analysis, we perform following steps to filter out variables and make them model ready.\n",
    "\n",
    "\n",
    "###### **Missing Values Analysis**\n",
    "\n",
    "What are missing values? In real world, the data are not always complete. There are numerous times when we get some observations with one or many variables values as missing. These data are not helpful in creating model and doing analysis. Hence, they need to be taken care of at the start of model making, or in the pre-processing stage.\n",
    "\n",
    "In our data, we found some variables with missing data. It can be observed from below missing values analysis table.\n",
    "\n",
    "\n",
    "**Missing Values count for each variable**\n",
    "\n",
    "| Variables | Missing_percentage |\n",
    "| --- | --- |\n",
    "| Body mass index | 4.189189 |\n",
    "| Absenteeism time in hours | 2.972973 |\n",
    "| Height | 1.891892 |\n",
    "| Work load Average/day | 1.351351 |\n",
    "| Education | 1.351351 |\n",
    "| Transportation expense | 0.945946 |\n",
    "| Son | 0.810811 |\n",
    "| Disciplinary failure | 0.810811 |\n",
    "| Hit target | 0.810811 |\n",
    "| Social smoker | 0.540541 |\n",
    "| Age | 0.405405 |\n",
    "| Reason for absence | 0.405405 |\n",
    "| Service time | 0.405405 |\n",
    "| Distance from Residence to Work | 0.405405 |\n",
    "| Social drinker | 0.405405 |\n",
    "| Pet | 0.270270 |\n",
    "| Weight | 0.135135 |\n",
    "| Month of absence | 0.135135 |\n",
    "| Seasons | 0.000000 |\n",
    "| Day of the week | 0.000000 |\n",
    "| ID | 0.000000 |\n",
    "\n",
    "Code used to evaluate missing values in the data:\n",
    "\n",
    "```\n",
    "#Create dataframe with missing percentage\n",
    "missing_val = pd.DataFrame(dataset.isnull().sum())\n",
    "\n",
    "#Reset index\n",
    "missing_val = missing_val.reset_index()\n",
    "\n",
    "#Rename variable\n",
    "missing_val = missing_val.rename(columns = {'index': 'Variables', 0: 'Missing_percentage'})\n",
    "```\n",
    "\n",
    "\n",
    "Hence we need to apply some algorithm to fill the missing variables for the above variables, as we can't drop any variable because the missing values for each variable is less than 30% (which could be threshhold for dropping a variable with missing values in a variable).\n",
    "\n",
    "After appling various imputation techniques, KNN imputation algorithm gives us the best and closest results. Therefore, we will be using KNN imputation with k=3 to impute missing values in our given data.\n",
    "\n",
    "Also we observed that observations where *Reason of absence* is 0 (not a code), *Absenteeism time in hours* is also 0 and vice versa. We used this information too to fill many missing values.\n",
    "\n",
    "**Outlier Analysis**\n",
    "\n",
    "What are outliers? Basically when the observations has some inconsitent data with the rest of dataset. It can be caused by number of things like poor data quality or contamination, low quality measurements, malfunction equipment and manual errors. Sometimes they are correct data but some exceptional cases.\n",
    "\n",
    "\n",
    "It can be detected by lots of ways, some of which are:\n",
    "* Graphical Tools\n",
    "    * Box plot\n",
    "    * QQ Plot\n",
    "    * Scatter Plots\n",
    "* Statistical Techniques\n",
    "    * Grubb's Technique (It will only work on those data which are uniformly distributed.)\n",
    "\n",
    "\n",
    "We are going to use the graphical tools to detect if we have any outliers in our data. In our case we used Box plots to analyze the data and observed below analysis:\n",
    "* For the variable *Absenteeism time in hours*, we observed that for a given day, the number of hours are greater than 24 hours for some observations, which should not possible. These data are 32, 40, 48, 56, 64, 80, 104, 112, 120. Hence we replaced this data with nan and applied KNN imputation to impute these observations.\n",
    "\n",
    "\n",
    "**Box Plots**\n",
    "\n",
    "*Refer to Appendix 1A (Code and figure)*\n",
    "\n",
    "## Correlation plot\n",
    "\n",
    "The correlation plot for the given data can be seen as below:\n",
    "\n",
    "![CorrelationAnalysis.jpg](CorrelationAnalysis.jpg)\n",
    "\n",
    "### Plots to explain the reason of Absenteeism\n",
    "\n",
    "We have gone through various plots to determine the reasons of Absenteeism. These plots include bar graphs and line graphs as follows:\n",
    "\n",
    "![GP_Age.jpg](GP_Age.jpg)\n",
    "![GP_Body%20mass%20index.jpg](GP_Body%20mass%20index.jpg)\n",
    "![GP_Distance.jpg](GP_Distance.jpg)\n",
    "![GP_Height.jpg](GP_Height.jpg)\n",
    "![GP_Hit%20target.jpg](GP_Hit%20target.jpg)\n",
    "![GP_Pet.jpg](GP_Pet.jpg)\n",
    "![GP_Service%20time.jpg](GP_Service%20time.jpg)\n",
    "![GP_Son.jpg](GP_Son.jpg)\n",
    "![GP_Transportation%20expense.jpg](GP_Transportation%20expense.jpg)\n",
    "![GP_Weight.jpg](GP_Weight.jpg)\n",
    "![GP_Work%20load.jpg](GP_Work%20load.jpg)\n",
    "![GP_Day.jpg](GP_Day.jpg)\n",
    "![GP_Disciplinary%20failure.jpg](GP_Disciplinary%20failure.jpg)\n",
    "![GP_Education.jpg](GP_Education.jpg)\n",
    "![GP_ID.jpg](GP_ID.jpg)\n",
    "![GP_Month.jpg](GP_Month.jpg)\n",
    "![GP_ROA.jpg](GP_ROA.jpg)\n",
    "![GP_Season.jpg](GP_Season.jpg)\n",
    "![GP_Social%20drinker.jpg](GP_Social%20drinker.jpg)\n",
    "![GP_Social%20smoker.jpg](GP_Social%20smoker.jpg)\n",
    "\n",
    "\n",
    "From all the above given graphs, following inferences can be made to get a clear picture for getting the reasons for absenteeism:\n",
    "* On start of the week, i.e. Mondays, most people tend to take leaves.\n",
    "\n",
    "* People, who don't properly face Disciplinary actions tend to take more leaves.\n",
    "\n",
    "* Employees who are High School graduates take more leaves compare to other employees with higher education.\n",
    "\n",
    "* In March, the number of employees taking leaves are more compared to other months.\n",
    "\n",
    "* Number of leaves decrease with owning more pets.\n",
    "\n",
    "* Employees take more leaves for medical consulation than any other ICD code, i.e. code 23.\n",
    "\n",
    "* Social drinker are more prone to be absent, than those who don't drink.\n",
    "\n",
    "* Social smoker are better able to come to work than those who don't smoke.\n",
    "\n",
    "With above inferences, following solutions can be provided to cope with Absenteeism. Each of the below solutions corresponds to the above given inference:\n",
    "* Since it's the day after weekends, Mondays are always blue. This is major issue faced by the industry. It can be solved by reducing the number of hours reduces on Mondays and compensating them in middle days of the week. This will encourage the employees to come to the office.\n",
    "\n",
    "* The company needs to be stricter, while implementing Disciplinary actions against the employees who are defaulting. This will create positive drive among the workers to book target accomplishments.\n",
    "\n",
    "* High School graduates are not professionals as such, i.e. they don't have industry experience, since they just got out of school environment. The company may provide 2-3 months training programmes to inculcate them with professional behaviour. Then they may have better understanding of the work culture.\n",
    "\n",
    "* In most of the countries, March is the end of financial year. This involves documenting various tax and finance related files and long queues of tax filings. This can be reduced if company can provide tax and finance consultations in the company itself, so that employees don't have to go out of the office for consultations.\n",
    "\n",
    "* In many research studies, it has been implied that pets are great stress reliever. Hence owning more pets, may help employees relax properly at home, so they can perform with full efficiency at work. Hence company can encourage the employees to own a pet, or may involve employees to get into NGO where they take care of abandoned animals. This can help the employees to relax more and work efficiently.\n",
    "\n",
    "* For reasons like medical consultations (Code 23), employees may not have to provide official consultations slips to apply for leave. This can create havoc as company have no way to track all these leaves for their authenticity. This can be solved if the companies can provide free medical consultations to all it's employees every quater or every two quaters.\n",
    "\n",
    "* Drinking creates lots of health risk, specially after the day people consume drinks, like hangovers and head aches. This compel the employees to take unplanned extra leaves, as they usually don't find themselves able to go to office the next day. Company can start programs to inform it's employess of the ill effects of consumption of liquor and may provide with activities to reduce the stress levels through other means.\n",
    "\n",
    "* According to research, cigarettes help to reduce stress levels of persons, as it has nicotine that reduces brain stress. This indicates that employees who are less stressed tend to come to company more. Company can provide stress reliver activities to reduce tention among it's employees and may encourage it's employees to involve in such activities rather than having harmful and ill effects of tobacco.\n",
    "\n",
    "## Data Preparation\n",
    "\n",
    "Now for the second problem, we need to estimate Absenteeism hours for the year of 2011. For that, we have *Month* data from July 2007 to July 2010. However, to apply it for Linear Regression we need to convert the Month data to numerical data, as we can't fit the model with Date time data.\n",
    "\n",
    "Hence we have added a column of *Year* in the dataframe and will take out sum of each month by grouping *Month* & *Year* data and create a seperate dataframe with the data.\n",
    "\n",
    "Now we will apply different models to forcast the data for the year 2011."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3\n",
    "\n",
    "## Model Selection\n",
    "\n",
    "In exploratory analysis stage, we arrived at the conclusion that the problem requires **Regression Model** and **Time series Model** to predict our dependent variable, i.e. *Absenteeism*.\n",
    "\n",
    "We have applied multiple classification model which will be explained in below sections. For choosing a regression model, we are going to use metrics like MSE (mean squared error), MAE (mean absolute error), RMSE (root mean square error).\n",
    "\n",
    "### Linear Regression\n",
    "\n",
    "In statistics, linear regression is a linear approach to modelling the relationship between a scalar response (or dependent variable) and one or more explanatory variables (or independent variables).\n",
    "\n",
    "In our case, we have applied linear regression with one independent variable, i.e. Months and one dependent variable i.e. Absenteeism in hours.\n",
    "\n",
    "After applying the model in our cleaned data, we can calculate below metrics for the model:\n",
    "\n",
    "| ModelName | MSE^ | MAE^ | RMSE^ |\n",
    "| -- | -- | -- | -- | -- |\n",
    "| **Linear Regression** | 553.434 | 19.37 | 23.52 |\n",
    "\n",
    "\n",
    "^*The meaning of each metrics are explained in Conclusion. Please refer to it for more details*\n",
    "\n",
    "These metrics tell us that model did not performed well on the data. Let's look into how other models perform on the given data.\n",
    "\n",
    "The performance of the model can be viewed with below plots.\n",
    "\n",
    "![graph.png](graph.jpg)\n",
    "![graph2.png](graph2.jpg)\n",
    "\n",
    "### Polynomial Regression\n",
    "\n",
    "In statistics, polynomial regression is a form of regression analysis in which the relationship between the independent variable x and the dependent variable y is modelled as an nth degree polynomial in x.\n",
    "\n",
    "For our data, the best performance is given when n=5, that is 5th degree polynomial equation.\n",
    "\n",
    "After applying the model in our cleaned data, we can calculate below metrics for the model:\n",
    "\n",
    "| ModelName | MSE^ | MAE^ | RMSE^ |\n",
    "| -- | -- | -- | -- | -- |\n",
    "| **Polynomial Regression** | 898.78 | 20.36 | 29.97 |\n",
    "\n",
    "^*The meaning of each metrics are explained in Conclusion. Please refer to it for more details*\n",
    "\n",
    "These metrics tell us that this model did not performed well on the data. Let's look into how other time series models perform on the given data.\n",
    "\n",
    "The performance of the model can be viewed with below plots.\n",
    "\n",
    "![graph3.jpg](graph3.jpg)\n",
    "\n",
    "### Time series analysis - ARIMA\n",
    "\n",
    "Time series analysis comprises methods for analyzing time series data in order to extract meaningful statistics and other characteristics of the data. Time series forecasting is the use of a model to predict future values based on previously observed values.\n",
    "\n",
    "For this, we did the indexing of data using time series data, starting from 2007-07-31 to 2010-07-31, as the total number of absent hours will be calculated at the end of each month from July 2007 - July 2010.\n",
    "\n",
    "We can also visualize our data using a method called time-series decomposition that allows us to decompose our time series into three distinct components: trend, seasonality, and noise. This can be seen using below plot:\n",
    "![decomposition.jpg](decomposition.jpg)\n",
    "\n",
    "We are going to apply one of the most commonly used method for time-series forecasting, known as ARIMA, which stands for Autoregressive Integrated Moving Average.\n",
    "\n",
    "ARIMA models are denoted with the notation ARIMA(p, d, q). These three parameters account for seasonality, trend, and noise in data.\n",
    "\n",
    "After applying various combinations p,d,q and observing AIC (Akaike information criterion), we set to choose this combination for best fit for the model:\n",
    "\n",
    "**ARIMA(1, 1, 0)x(1, 1, 0, 12)12 - AIC:40.166185689188175**\n",
    "\n",
    "With this combination, we created ARIMA model. The results can be seen in below plot:\n",
    "\n",
    "![arima.jpg](arima.jpg)\n",
    "\n",
    "The summary of the model can be seen as below:\n",
    "\n",
    "![Capture.jpg](Capture.jpg)\n",
    "\n",
    "After applying the model in our cleaned data, we can calculate below metrics for the model:\n",
    "\n",
    "| ModelName | MSE^ | MAE^ | RMSE^ |\n",
    "| -- | -- | -- | -- | -- |\n",
    "| **ARIMA** | 1115.38 | 26.48 | 33.39 |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "## Model Evaluation\n",
    "\n",
    "As we have seen in previous section, as we tried on different models, we came across different results. To evaluate a regression model, following metrics are used.\n",
    "\n",
    "* **Mean Square Error**:  The mean squared error (MSE) of an estimator (of a procedure for estimating an unobserved quantity) measures the average of the squares of the errors—that is, the average squared difference between the estimated values and what is estimated. This is given by, \n",
    "\n",
    "* **Mean Absolute Error**: The mean absolute error (MAE) is a measure of difference between two continuous variable. This can be calculated by, \n",
    "![MAE.jpg](MAE.jpg)\n",
    "* **Root Mean Square Error**: The root-mean-square error (RMSE) is a frequently used measure of the differences between values (sample or population values) predicted by a model or an estimator and the values observed. The RMSE represents the square root of the second sample moment of the differences between predicted values and observed values or the quadratic mean of these differences\n",
    "![RIq96.jpg](RIq96.jpg)\n",
    "    \n",
    "These metrics help us to choose from different models we create. Based on these, we came across below data, regarding the performance of a model.\n",
    "\n",
    "| ModelName | MSE^ | MAE^ | RMSE^ |\n",
    "| -- | -- | -- | -- | -- |\n",
    "| **Linear Regression** | 553.434 | 19.37 | 23.52 |\n",
    "| **Polynomial Regression** | 898.78 | 20.36 | 29.97 |\n",
    "| **ARIMA** | 1115.38 | 26.48 | 33.39 |\n",
    "\n",
    "## Model Selection\n",
    "\n",
    "From the above table, we can clearly see that  **Linear Regression** model works better than the rest of the n=models. Hence we will go with Linear Regression to predict the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix 1 - Univariate Analysis Graphs\n",
    "\n",
    "## A) Box Plots\n",
    "\n",
    "What are Box plots? A box plot is a method for graphically depicting groups of numerical data through their quartiles.\n",
    "\n",
    "Box plots for each numerical data are shown below:\n",
    "\n",
    "![1.jpg](1.jpg)\n",
    "![2.jpg](2.jpg)\n",
    "![3.jpg](3.jpg)\n",
    "![4.jpg](4.jpg)\n",
    "![5.jpg](5.jpg)\n",
    "![6.jpg](6.jpg)\n",
    "![7.jpg](7.jpg)\n",
    "![8.jpg](8.jpg)\n",
    "![9.jpg](9.jpg)\n",
    "![10.jpg](10.jpg)\n",
    "![11.jpg](11.jpg)\n",
    "![12.jpg](12.jpg)\n",
    "![13.jpg](13.jpg)\n",
    "![14.jpg](14.jpg)\n",
    "\n",
    "\n",
    "\n",
    "**Code used to create boxplots:**\n",
    "\n",
    "```\n",
    "def CreateBoxPlot(dataset, columnNames):\n",
    "    fig = plt.figure(1, figsize=(9, 6))\n",
    "    #ax = fig.add_subplot(111)\n",
    "    bp = plt.boxplot(dataset[columnNames], patch_artist=True)\n",
    "    \n",
    "    for box in bp['boxes']:\n",
    "        # change outline color\n",
    "        box.set( color='#7570b3', linewidth=2)\n",
    "        # change fill color\n",
    "        box.set( facecolor = '#1b9e77' )\n",
    "    \n",
    "    for whisker in bp['whiskers']:\n",
    "        whisker.set(color='#7570b3', linewidth=2)\n",
    "    \n",
    "    for cap in bp['caps']:\n",
    "        cap.set(color='#7570b3', linewidth=2)\n",
    "\n",
    "    for median in bp['medians']:\n",
    "        median.set(color='#b2df8a', linewidth=2)\n",
    "\n",
    "    for flier in bp['fliers']:\n",
    "        flier.set(marker='o', color='#e7298a', alpha=0.5)\n",
    "    \n",
    "    plt.xlabel(columnNames)\n",
    "    \n",
    "    filename = \"D:\\\\edWisor\\\\Project-I\\\\Boxplot Figures\\\\\"+columnNames+' boxplot.png'\n",
    "    fig.savefig(filename, bbox_inches='tight')\n",
    "    return filename\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
